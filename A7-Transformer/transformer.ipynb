{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3253cce9-bba3-4a1b-b29c-636279f2bb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['if structural reforms simply lower all wages and prices , it may indeed be difficult in the short-term to counter the drop in aggregate demand .', '如果 结构 改革 降低 了 所有 工资 和 物价 ， 那么 克服 短期 总需求 下降 的确 十分困难 。']\n",
      "Epoch: 0001, Loss: 3.021563\n",
      "Epoch: 0002, Loss: 2.666291\n",
      "Epoch: 0003, Loss: 2.346162\n",
      "Epoch: 0004, Loss: 2.047945\n",
      "Epoch: 0005, Loss: 1.762816\n",
      "Epoch: 0006, Loss: 1.488882\n",
      "Epoch: 0007, Loss: 1.229650\n",
      "Epoch: 0008, Loss: 0.991173\n",
      "Epoch: 0009, Loss: 0.779623\n",
      "Epoch: 0010, Loss: 0.599071\n",
      "Epoch: 0011, Loss: 0.451447\n",
      "Epoch: 0012, Loss: 0.335408\n",
      "Epoch: 0013, Loss: 0.247433\n",
      "Epoch: 0014, Loss: 0.182554\n",
      "Epoch: 0015, Loss: 0.135583\n",
      "Epoch: 0016, Loss: 0.101789\n",
      "Epoch: 0017, Loss: 0.077460\n",
      "Epoch: 0018, Loss: 0.059849\n",
      "Epoch: 0019, Loss: 0.047009\n",
      "Epoch: 0020, Loss: 0.037548\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "import torch \n",
    "import torch.optim as optim\n",
    "import numpy as np \n",
    "import torch.nn as nn \n",
    "\n",
    "import torchtext \n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import data\n",
    "import math\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from torch.nn.functional import pad, log_softmax\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.data import get_tokenizer\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def read_file(json_path):\n",
    "    datas=[]\n",
    "    tokenizer = get_tokenizer('basic_english')\n",
    "    with open(json_path, 'r', encoding=\"utf-8\") as fp:\n",
    "        lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            line = json.loads(line)\n",
    "            for i in line:\n",
    "                english, chinese = i[0], i[1]\n",
    "                   \n",
    "            english = tokenizer(english)       \n",
    "            chinese = list(jieba.cut(chinese))     \n",
    "            \n",
    "            english = \" \".join(english)\n",
    "            chinese = \" \".join(chinese)             \n",
    "            datas.append([english,chinese])       \n",
    "\n",
    "    return datas\n",
    "\n",
    "trainDatas = read_file('/home/yhz2023/code_file/train.json')\n",
    "print(trainDatas[0])\n",
    "\n",
    "class TranslationCorpus:\n",
    "    def __init__(self):\n",
    "        self.trainDatas = trainDatas\n",
    "        self.x_max_len = max(len(row[0].split()) for row in trainDatas) + 1  \n",
    "        self.y_max_len = max(len(row[1].split()) for row in trainDatas) + 2  \n",
    "        \n",
    "        x_datas = Counter(word for row in self.trainDatas for word in row[0].split())\n",
    "        y_datas = Counter(word for row in self.trainDatas for word in row[1].split())  \n",
    "        \n",
    "        x_vocab = {'<pad>': 0, **{word: i+1 for i, word in enumerate(x_datas)}}                    \n",
    "        y_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, **{word: i+3 for i, word in enumerate(y_datas)}} \n",
    "        self.x_vocab, self.y_vocab = x_vocab, y_vocab\n",
    "\n",
    "        self.x_idx2word = {v: k for k, v in self.x_vocab.items()}\n",
    "        self.y_idx2word = {v: k for k, v in self.y_vocab.items()}\n",
    "\n",
    "    def make_batch(self, batch_size, test_batch=False):\n",
    "        input_batch, output_batch, target_batch = [], [], [] \n",
    "        \n",
    "        # 随机选择句子索引\n",
    "        shuffleDatas = torch.randperm(len(self.trainDatas))[:batch_size] \n",
    "\n",
    "        for index in shuffleDatas:            \n",
    "            \n",
    "            x_sentence, y_sentence = self.trainDatas[index]           \n",
    "            x_sentence_key = [self.x_vocab[word] for word in x_sentence.split()]\n",
    "            y_sentence_key = [self.y_vocab[word] for word in y_sentence.split()]               \n",
    "         \n",
    "            x_sentence_key_all = x_sentence_key + [self.x_vocab['<pad>']] * (self.x_max_len - len(x_sentence_key))\n",
    "            y_sentence_key_all = [self.y_vocab['<sos>']] + y_sentence_key + [self.y_vocab['<eos>']]\n",
    "            y_sentence_key_all = y_sentence_key_all + [self.y_vocab['<pad>']] * (self.y_max_len - len(y_sentence_key_all)) \n",
    "           \n",
    "            decode_x_sentence_key_all=[self.y_vocab['<sos>']] + ([self.y_vocab['<pad>']] * (self.y_max_len - 2))     if test_batch else y_sentence_key_all[:-1] \n",
    "\n",
    "            input_batch.append(x_sentence_key_all)              \n",
    "            output_batch.append( decode_x_sentence_key_all )    \n",
    "            target_batch.append(y_sentence_key_all[1:])      \n",
    "           \n",
    "        x = torch.LongTensor(input_batch)              \n",
    "        decode_x = torch.LongTensor(output_batch)       \n",
    "        y = torch.LongTensor(target_batch)              \n",
    "        return x, decode_x, y\n",
    "\n",
    "corpus = TranslationCorpus()\n",
    "batch_size = 64\n",
    "x, decode_x, y = corpus.make_batch(batch_size) \n",
    "\n",
    "d_k = 64          \n",
    "d_v = 64           \n",
    "d_embedding = 512  \n",
    "n_heads = 8         \n",
    "n_layers = 6        \n",
    "\n",
    "# 词表长度\n",
    "x_vocab_len=len(corpus.x_vocab)\n",
    "y_vocab_len=len(corpus.y_vocab) \n",
    "\n",
    "# 位置编码长度\n",
    "x_pos_emb_len=corpus.x_max_len+1\n",
    "y_pos_emb_len=corpus.y_max_len+1\n",
    "\n",
    "\n",
    "# 多头自注意力类\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W_Q = nn.Linear(d_embedding, d_k * n_heads) \n",
    "        self.W_K = nn.Linear(d_embedding, d_k * n_heads) \n",
    "        self.W_V = nn.Linear(d_embedding, d_v * n_heads) \n",
    "        self.linear = nn.Linear(n_heads * d_v, d_embedding)\n",
    "        self.layer_norm = nn.LayerNorm(d_embedding)\n",
    "\n",
    "        \n",
    "    def forward(self, Q, K, V, encodePadMask):  \n",
    "        residual, batch_size = Q, Q.shape[0]\n",
    "\n",
    "        QQ = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1,2) \n",
    "        KK = self.W_K(K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  \n",
    "        VV = self.W_V(V).view(batch_size, -1, n_heads, d_v).transpose(1,2)    \n",
    "\n",
    "        encodePadMask = encodePadMask.unsqueeze(1).repeat(1, n_heads, 1, 1) \n",
    "                        \n",
    "        scaled_attention = torch.matmul(QQ, KK.transpose(-1, -2)) / np.sqrt(d_k)       \n",
    "        scaled_attention.masked_fill_(encodePadMask, -1e9) \n",
    "        attention_weight = nn.Softmax(dim=-1)(scaled_attention)       \n",
    "        \n",
    "        context = torch.matmul(attention_weight, VV)   \n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v)       \n",
    "        output = self.linear(context)         \n",
    "        output = self.layer_norm(output + residual)           \n",
    "        return output, attention_weight \n",
    "\n",
    "# 前馈网络类\n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self, d_ff=2048):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=d_embedding, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_embedding, kernel_size=1)\n",
    "        self.layer_norm = nn.LayerNorm(d_embedding)\n",
    "\n",
    "    def forward(self, inputs):                               \n",
    "        residual = inputs \n",
    "        output = nn.ReLU()(self.conv1(inputs.transpose(1, 2)))\n",
    "        output = self.conv2(output).transpose(1, 2)    \n",
    "        output = self.layer_norm(output + residual)         \n",
    "        \n",
    "        return output\n",
    "\n",
    "def PositionalEncoding(n_position, embedding_dim):     \n",
    "    position_table = np.zeros((n_position, embedding_dim)) \n",
    "    for pos_i in range(n_position):\n",
    "        for hid_j in range(embedding_dim):\n",
    "            angle = pos_i / np.power(10000, 2 * (hid_j // 2) / embedding_dim)\n",
    "            position_table[pos_i, hid_j] = angle    \n",
    "    \n",
    "    position_table[:, 0::2] = np.sin(position_table[:, 0::2])  \n",
    "    position_table[:, 1::2] = np.cos(position_table[:, 1::2])  \n",
    "      \n",
    "    return torch.FloatTensor(position_table) \n",
    "\n",
    "def encode_pad_mask(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)   \n",
    "    pad_attn_mask = pad_attn_mask.expand(batch_size, len_q, len_k)    \n",
    "    return pad_attn_mask\n",
    "\n",
    "def decoder_subsequent_mask(seq):\n",
    "    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]  \n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1)\n",
    "    subsequent_mask = torch.from_numpy(subsequent_mask).byte()   \n",
    "    return subsequent_mask \n",
    "\n",
    "# 编码器层\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.multiHeadAttention = MultiHeadAttention()            \n",
    "        self.poswiseFeedForwardNet = PoswiseFeedForwardNet()   \n",
    "    def forward(self, x, encodePadMask): \n",
    "        encode_output, encode_attention_weight = self.multiHeadAttention(x,x,x,encodePadMask)    \n",
    "        encode_output = self.poswiseFeedForwardNet(encode_output) \n",
    "       \n",
    "        return encode_output, encode_attention_weight \n",
    "\n",
    "# 编码器\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.x_emb = nn.Embedding(x_vocab_len, d_embedding) \n",
    "        self.pos_emb = nn.Embedding.from_pretrained( PositionalEncoding(x_pos_emb_len, d_embedding) , freeze=True) \n",
    "        self.layers = nn.ModuleList(EncoderLayer() for _ in range(n_layers))\n",
    "    def forward(self, x):  \n",
    "        pos_ids = torch.arange(1, x.size(1) + 1).unsqueeze(0).to(x)\n",
    "        x_pos_emb = self.x_emb(x) + self.pos_emb(pos_ids)\n",
    "        encodePadMask = encode_pad_mask(x, x)\n",
    "        encode_attention_weights = []\n",
    "\n",
    "        for layer in self.layers: \n",
    "            encode_output, encode_attention_weight = layer(x_pos_emb, encodePadMask)\n",
    "            encode_attention_weights.append(encode_attention_weight)\n",
    "        return encode_output, encode_attention_weights\n",
    "\n",
    "# 解码器层\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.maskMultiHeadAttention = MultiHeadAttention()    \n",
    "        self.multiHeadAttention = MultiHeadAttention()          \n",
    "        self.pos_ffn = PoswiseFeedForwardNet()            \n",
    "    def forward(self, decode_x, encode_output, encodePadMask_add_decoderSubsequentMask, encodePadMask_decodeX_x): \n",
    "        mask_decoder_output, mask_decoder_attention_weight = self.maskMultiHeadAttention(decode_x, decode_x, decode_x, encodePadMask_add_decoderSubsequentMask)\n",
    "        decoder_output, decoder_attention_weight = self.multiHeadAttention(mask_decoder_output, encode_output, encode_output, encodePadMask_decodeX_x)       \n",
    "        decoder_output = self.pos_ffn(decoder_output)\n",
    "        return decoder_output, mask_decoder_attention_weight, decoder_attention_weight\n",
    "\n",
    "#  解码器\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.y_emb = nn.Embedding(y_vocab_len, d_embedding) \n",
    "        self.pos_emb = nn.Embedding.from_pretrained( PositionalEncoding(y_pos_emb_len, d_embedding), freeze=True)     \n",
    "        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
    "    def forward(self, decode_x, x, encode_output): \n",
    "        pos_ids = torch.arange(1, decode_x.size(1) + 1).unsqueeze(0).to(decode_x)\n",
    "        y_pos_emb = self.y_emb(decode_x) + self.pos_emb(pos_ids)        \n",
    "        encodePadMask_decodeX_decodeX = encode_pad_mask(decode_x, decode_x)    \n",
    "        decoderSubsequentMask = decoder_subsequent_mask(decode_x)\n",
    "\n",
    "        encodePadMask_add_decoderSubsequentMask = torch.gt((encodePadMask_decodeX_decodeX + decoderSubsequentMask), 0) \n",
    "        encodePadMask_decodeX_x = encode_pad_mask(decode_x, x)   \n",
    "       \n",
    "        mask_decoder_attention_weights, decoder_attention_weights = [], [] \n",
    "       \n",
    "        for layer in self.layers:\n",
    "            decoder_output, mask_decoder_attention_weight, decoder_attention_weight = layer(y_pos_emb, encode_output, encodePadMask_add_decoderSubsequentMask, encodePadMask_decodeX_x)\n",
    "            mask_decoder_attention_weights.append(mask_decoder_attention_weight)\n",
    "            decoder_attention_weights.append(decoder_attention_weight)        \n",
    "          \n",
    "        return decoder_output, mask_decoder_attention_weights, decoder_attention_weights\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.encoder = Encoder()        \n",
    "        self.decoder = Decoder() \n",
    "        self.projection = nn.Linear(d_embedding, y_vocab_len, bias=False)\n",
    "        \n",
    "    def forward(self, x, decode_x):    \n",
    "        encode_output, encode_attention_weights = self.encoder(x)\n",
    "        decoder_output, mask_decoder_attention_weights, decoder_attention_weights = self.decoder(decode_x, x, encode_output)\n",
    "        outputs = self.projection(decoder_output)  \n",
    "     \n",
    "        return outputs, encode_attention_weights, mask_decoder_attention_weights, decoder_attention_weights\n",
    "\n",
    "def tokens_to_sentence(tokens, idx2word):\n",
    "    return [idx2word[token] for token in tokens if token != corpus.y_vocab['<pad>']]  # Excluding padding\n",
    "\n",
    "def calculate_bleu(model, data_loader, corpus):\n",
    "    model.eval()\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, decode_x, y in data_loader:\n",
    "            outputs, _, _, _ = model(x, decode_x)\n",
    "            _, predicted_indices = torch.max(outputs, dim=2)\n",
    "\n",
    "            # Convert predicted indices to words\n",
    "            for i in range(predicted_indices.size(0)):\n",
    "                hypothesis = tokens_to_sentence(predicted_indices[i].tolist(), corpus.y_idx2word)\n",
    "                reference = [tokens_to_sentence(y[i].tolist(), corpus.y_idx2word)]\n",
    "                \n",
    "                hypotheses.append(hypothesis)\n",
    "                references.append(reference)\n",
    "\n",
    "    # Calculate BLEU score\n",
    "    bleu_score = corpus_bleu(references, hypotheses)\n",
    "    return bleu_score\n",
    "    \n",
    "model = Transformer() \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001) \n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad() \n",
    "    x, decode_x, y = corpus.make_batch(batch_size) # 创建训练数据-[编码器输入,解码器输入,目标数据]    \n",
    "    outputs, _, _, _ = model(x, decode_x) # 获取模型输出 \n",
    "    loss = criterion(outputs.view(-1, y_vocab_len), y.view(-1)) \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        bleu_score = calculate_bleu(model, [corpus.make_batch(batch_size, test_batch=True) for _ in range(10)], corpus)\n",
    "        print(f\"Epoch: {epoch + 1:04d}, Loss: {loss:.6f}\")\n",
    "    loss.backward()     \n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c22515f-a3b3-4e1f-a306-107c4c954304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
